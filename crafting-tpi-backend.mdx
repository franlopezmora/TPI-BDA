---
title: "Diseñando el Backend de un Sistema de Pruebas de Manejo"
date: "02-09-2025"
description: "Un relato sobre la construcción de una arquitectura de microservicios para gestionar pruebas de manejo, desde las decisiones de diseño hasta el trabajo en equipo."
---

Hace unos meses arrancamos con un desafío ambicioso: construir, como parte del **Trabajo Práctico Integrador** de Backend, un sistema completo para gestionar **pruebas de manejo**. No queríamos quedarnos en lo académico; queríamos acercarnos a la realidad de una aplicación moderna, con microservicios, bases de datos reales y despliegues en contenedores. En este ensayo voy a contarte las decisiones que tomamos y cómo las implementamos.

## Arquitectura y microservicios

Desde el principio optamos por una **arquitectura de microservicios**, porque nos permitía dividir el dominio en piezas independientes y trabajar de manera paralela. Terminamos con seis servicios principales:

- **tpi-admin-service (8081)**: centraliza la gestión de empleados, interesados, pruebas y zonas peligrosas:contentReference[oaicite:0]{index=0}.
- **tpi-vehiculos-service (8082)**: administra vehículos y sus relaciones:contentReference[oaicite:1]{index=1}.
- **tpi-reportes-service (8083)**: genera reportes y estadísticas a partir de la información acumulada:contentReference[oaicite:2]{index=2}.
- **tpi-notificaciones-service (8084)**: envía notificaciones a través de un webhook de Discord, lo que nos permitió tener feedback inmediato cuando se registraba una prueba:contentReference[oaicite:3]{index=3}.
- **tpi-pruebas-service (8085)**: maneja toda la lógica específica de las pruebas de manejo:contentReference[oaicite:4]{index=4}.
- **tpi-gateway-service (8080)**: actúa como **API Gateway** y punto de entrada único, enrutando las solicitudes al microservicio correspondiente:contentReference[oaicite:5]{index=5}.

Esta división nos obligó a pensar en los contratos entre servicios y a utilizar **Spring Cloud Gateway** para centralizar la autenticación y el enrutamiento:contentReference[oaicite:6]{index=6}. Cada microservicio tiene su propia base de datos, lo que simplifica la consistencia interna y reduce acoplamientos.

## Tecnologías y herramientas

Elegimos **Java 21** como lenguaje base y **Spring Boot 3.3.5** como framework, aprovechando su soporte para microservicios y la madurez de su ecosistema:contentReference[oaicite:7]{index=7}. Para la persistencia usamos **Spring Data JPA** y **PostgreSQL** como base de datos principal, mientras que **H2** nos sirvió para testear en memoria:contentReference[oaicite:8]{index=8}. Para el cliente HTTP declarativo utilizamos **OpenFeign** y documentamos cada API con **SpringDoc OpenAPI**:contentReference[oaicite:9]{index=9}. La construcción y gestión de dependencias se resolvieron con **Maven**:contentReference[oaicite:10]{index=10}.

Aunque nuestro foco era el backend, también había un frontend en **Next.js 15.4.3** con **React 19.1.0** y **TailwindCSS 4**:contentReference[oaicite:11]{index=11}:contentReference[oaicite:12]{index=12}, lo que nos permitió probar los endpoints de manera interactiva. A nivel DevOps nos apoyamos en **Docker** y **Docker Compose** para orquestar todos los servicios:contentReference[oaicite:13]{index=13}.

## Base de datos y comunicación

Optamos por **PostgreSQL 15** como motor de base de datos y empaquetamos su inicialización en un script ubicado en `/docker/db/init.sql`:contentReference[oaicite:14]{index=14}. Cada microservicio se conecta a su propia instancia, con usuarios y contraseñas definidos como variables de entorno por defecto (`postgres/postgres`):contentReference[oaicite:15]{index=15}. Para las pruebas automatizadas utilizamos **H2** porque facilita la ejecución de tests en memoria sin depender de un contenedor externo:contentReference[oaicite:16]{index=16}. La comunicación entre microservicios se realiza via HTTP REST y, cuando fue necesario, utilizamos Feign para simplificar llamadas internas.

## Gateway y unificación

El **API Gateway** no es solo un router; también nos permitió concentrar políticas comunes como el manejo de errores, la documentación y los puntos de control. Exponemos todos los endpoints a través del puerto **8080**, y cada microservicio mantiene su URL interna:contentReference[oaicite:17]{index=17}. También configuramos **Spring Cloud Gateway** para exponer la documentación Swagger en un único punto (`/swagger-ui.html`):contentReference[oaicite:18]{index=18}.

## Notificaciones y servicios externos

Una de las particularidades del proyecto fue el servicio de notificaciones. En lugar de enviar correos tradicionales, decidimos integrar un **webhook de Discord**: cada vez que se crea una nueva prueba o se registra un interesado, se dispara un mensaje en un canal que utilizamos para seguimiento:contentReference[oaicite:19]{index=19}. Para configurarlo, basta con cambiar la URL del webhook en el archivo de configuración del microservicio:contentReference[oaicite:20]{index=20}.

## Desarrollo, scripts y despliegue

Queríamos que el entorno de desarrollo fuera lo más simple posible. Por eso escribimos un script `build-all.sh` que compila todos los microservicios, construye las imágenes y levanta todo el stack con `docker-compose up --build`:contentReference[oaicite:21]{index=21}. También preparamos instrucciones para ejecutar los servicios manualmente con Maven y levantar la base de datos por separado:contentReference[oaicite:22]{index=22}. Para reiniciar desde cero, basta con ejecutar `docker-compose down -v` y volver a correr el script de build:contentReference[oaicite:23]{index=23}.

Pensamos en el despliegue productivo y dejamos pautas claras: configurar variables de entorno específicas, usar una base de datos externa, montar un reverse proxy con SSL y habilitar monitoreo y logging:contentReference[oaicite:24]{index=24}. Todo esto quedó documentado para que cualquiera pueda replicar o mejorar el proyecto.

## Testing y calidad

Cada microservicio incluye tests unitarios y de integración. Establecimos un estándar: ninguna feature se mergea sin sus tests correspondientes. Con `mvn test` se ejecutan todos los tests de un servicio o del proyecto completo:contentReference[oaicite:25]{index=25}, lo que nos dio confianza para refactorizar sin miedo.

## Equipo y aprendizajes

Nada de esto hubiera sido posible sin el equipo. Trabajé junto a **Nicolás Garay**, **Mariano Iturriza** y **Marcos Belli**, y cada uno tomó ownership de un microservicio diferente:contentReference[oaicite:26]{index=26}. Esto nos permitió avanzar en paralelo y luego integrar en el gateway. Nos enfrentamos a problemas reales: sincronizar esquemas de base de datos, definir contratos de API, manejar errores asincrónicos y organizar nuestro repositorio para que fuese fácil de navegar:contentReference[oaicite:27]{index=27}.

## Lo que se viene

Aunque cumplimos con los requisitos académicos, el proyecto tiene mucho potencial. Nos gustaría añadir autenticación y autorización con JWT, refinar el sistema de notificaciones para que sea configurable (correo, SMS, Discord), y desplegarlo en una plataforma en la nube para probar su escalabilidad. También estamos considerando agregar monitoreo con Prometheus y Grafana y automatizar los despliegues con CI/CD.

## Cierre

Construir el backend de este sistema de pruebas de manejo fue más que una tarea universitaria; fue una inmersión en el diseño de sistemas modernos. Dividir el dominio en microservicios nos obligó a comunicarnos y a documentar cada decisión. Los contenedores, los scripts de despliegue y las pruebas nos enseñaron a pensar en la confiabilidad desde el primer día. Más importante aún, trabajar en equipo nos mostró que el código es la excusa para aprender a colaborar. Y aunque el proyecto ya funciona, sabemos que todavía queda mucho por explorar y mejorar.

